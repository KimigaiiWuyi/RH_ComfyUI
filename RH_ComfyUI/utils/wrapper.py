import random
from typing import Tuple, Optional, Annotated

from PIL import Image
from msgspec import Meta

from gsuid_core.logger import logger
from gsuid_core.models import Event
from gsuid_core.segment import MessageSegment
from gsuid_core.ai_core.register import ai_tools
from gsuid_core.utils.resource_manager import RM

from .model_wrapper import (
    recommend_model,
)
from .comfyui._request import (
    draw_img_by_qwen_2512,
    gen_music_by_ace_step_1_5,
    gen_speech_by_index_tts_2,
    edit_img_by_qwen_edit_2511,
    gen_video_by_img_by_wan2_2,
    gen_video_by_text_by_wan2_2,
    draw_img_by_img_by_qwen_2512,
)
from ..utils.blt.request import (
    edit_img_by_banana2,
    draw_image_by_banana2,
    edit_img_by_banana_pro,
    draw_image_by_banana_pro,
)
from ..utils.database.models import RHBind
from ..rh_config.comfyui_config import RHCOMFYUI_CONFIG

Draw_Point: int = RHCOMFYUI_CONFIG.get_config("Draw_Point").data
Edit_Image_Point: int = RHCOMFYUI_CONFIG.get_config("Edit_Image_Point").data
Music_Point: int = RHCOMFYUI_CONFIG.get_config("Music_Point").data
Speech_Point: int = RHCOMFYUI_CONFIG.get_config("Speech_Point").data
Video_Point: int = RHCOMFYUI_CONFIG.get_config("Video_Point").data

text2image_workflow = {
    "qwen_2512": draw_img_by_qwen_2512,
    "banana2": draw_image_by_banana2,
    "banana_pro": draw_image_by_banana_pro,
}

image2image_workflow = {
    "qwen_2512_img2img": draw_img_by_img_by_qwen_2512,
}

image_edit_workflow = {
    "qwen_2511": edit_img_by_qwen_edit_2511,
    "banana2": edit_img_by_banana2,
    "banana_pro": edit_img_by_banana_pro,
}

music_workflow = {
    "ace_step1.5": gen_music_by_ace_step_1_5,
}

speech_workflow = {
    "IndexTTS2": gen_speech_by_index_tts_2,
}

text2video_workflow = {
    "wan2.2_text2video": gen_video_by_text_by_wan2_2,
}

image2video_workflow = {
    "wan2.2_img2video": gen_video_by_img_by_wan2_2,
}


async def check_point(ev: Event, point: int) -> Tuple[bool, str]:
    """
    æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç§¯åˆ†
    """
    logger.info(f"[RHComfyUI] check_point: ç”¨æˆ·:{ev.user_id} BotID:{ev.bot_id} æ¶ˆè´¹:{point}")

    bind = await RHBind.deduct_point(
        ev.user_id,
        ev.bot_id,
        point,
    )

    if bind:
        return True, f"ğŸ’ª ç§¯åˆ†å……è¶³ï¼å·²æ‰£é™¤{point}ç§¯åˆ†!\nâœ… æ­£åœ¨ç”Ÿæˆï¼Œé¢„è®¡å°†ç­‰å¾…1åˆ†é’Ÿ..."
    else:
        return False, f"âŒ ç§¯åˆ†ä¸è¶³ï¼éœ€è¦{point}ç§¯åˆ†ï¼"


@ai_tools(check_func=check_point, point=Draw_Point)
async def gen_image_by_text(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„æç¤ºè¯")],
    w: Annotated[int, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„å®½åº¦")] = 720,
    h: Annotated[int, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„é«˜åº¦")] = 1280,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
    model_knowledge: Annotated[Optional[str], Meta(description="æ¨¡å‹çŸ¥è¯†å‚è€ƒï¼Œç”±AIæ ¹æ®ç”¨æˆ·éœ€æ±‚é¢„å…ˆæ£€ç´¢")] = None,
) -> Image.Image:
    """
    æ–‡ç”Ÿå›¾å·¥å…·ï¼šæ ¹æ®æ–‡å­—æè¿°ç”Ÿæˆå›¾ç‰‡

    é€‚ç”¨äºï¼š
    - éœ€è¦ä»é›¶å¼€å§‹åˆ›å»ºå›¾ç‰‡çš„åœºæ™¯
    - åˆ›æ„è®¾è®¡ã€æ’ç”»ã€æµ·æŠ¥ç­‰è§†è§‰å†…å®¹ç”Ÿæˆ
    - æ ¹æ®æ–‡å­—æè¿°ç”Ÿæˆæ¦‚å¿µå›¾æˆ–ç¤ºæ„å›¾
    - å„ç§è‰ºæœ¯é£æ ¼çš„å›¾åƒåˆ›ä½œï¼ˆå†™å®ã€åŠ¨æ¼«ã€æ²¹ç”»ç­‰ï¼‰

    å¯ç”¨æ¨¡å‹ï¼š
    - qwen_2512: é€šä¹‰åƒé—®é«˜è´¨é‡æ–‡ç”Ÿå›¾æ¨¡å‹ï¼Œæ”¯æŒå¤šç§é£æ ¼
    - banana2: é«˜æ•ˆè½»é‡çº§æ–‡ç”Ÿå›¾æ¨¡å‹
    - banana_pro: é«˜è´¨é‡æ–‡ç”Ÿå›¾ä¸“ä¸šæ¨¡å‹

    æ ¹æ®ç”¨æˆ·å¯¹è´¨é‡ã€é€Ÿåº¦ã€æˆæœ¬çš„è¦æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹
    """
    if model is None:
        # å‘åå…¼å®¹ï¼šå¦‚æœAIæ²¡æœ‰é€‰æ‹©æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰çš„RAGæ–¹å¼
        try:
            model = await recommend_model(
                query=f"ç”Ÿæˆå›¾ç‰‡: {prompt}",
                category="text2image",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(text2image_workflow.keys()))

    if model is None:
        model = random.choice(list(text2image_workflow.keys()))

    if model_knowledge:
        logger.info(f"[RHComfyUI] ä½¿ç”¨AIé€‰æ‹©çš„æ¨¡å‹: {model} (åŸºäºçŸ¥è¯†æ£€ç´¢)")

    model_func = text2image_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(prompt, w, h)
    return result


@ai_tools(check_func=check_point, point=Draw_Point)
async def gen_image_by_img(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„æç¤ºè¯")],
    image_id: Annotated[str, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„åŸºç¡€å›¾ç‰‡ID")],
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
    model_knowledge: Annotated[Optional[str], Meta(description="æ¨¡å‹çŸ¥è¯†å‚è€ƒï¼Œç”±AIæ ¹æ®ç”¨æˆ·éœ€æ±‚é¢„å…ˆæ£€ç´¢")] = None,
) -> Image.Image:
    """
    å›¾ç”Ÿå›¾å·¥å…·ï¼šä»¥ç°æœ‰å›¾ç‰‡ä¸ºåŸºç¡€ï¼Œæ ¹æ®æ–‡å­—æè¿°ç”Ÿæˆæ–°å›¾ç‰‡

    é€‚ç”¨äºï¼š
    - åŸºäºå·²æœ‰å›¾ç‰‡è¿›è¡Œé‡æ–°ç»˜å›¾, ä¿ç•™åŸå›¾å¤§éƒ¨åˆ†å†…å®¹ç”Ÿæˆå…¨æ–°çš„å›¾ç‰‡

    å¯ç”¨æ¨¡å‹ï¼š
    - qwen_2512_img2img: é€šä¹‰åƒé—®å›¾ç”Ÿå›¾æ¨¡å‹ï¼Œæ”¯æŒé«˜è´¨é‡é£æ ¼è½¬æ¢
    """
    if model is None:
        # å‘åå…¼å®¹ï¼šå¦‚æœAIæ²¡æœ‰é€‰æ‹©æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰çš„RAGæ–¹å¼
        try:
            model = await recommend_model(
                query=f"å›¾ç”Ÿå›¾: {prompt}",
                category="image2image",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(image2image_workflow.keys()))

    if model is None:
        model = random.choice(list(image2image_workflow.keys()))

    if model_knowledge:
        logger.info(f"[RHComfyUI] ä½¿ç”¨AIé€‰æ‹©çš„æ¨¡å‹: {model} (åŸºäºçŸ¥è¯†æ£€ç´¢)")

    model_func = image2image_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")

    image = await RM.get(image_id)
    result = await model_func(prompt, image)
    return result


@ai_tools(check_func=check_point, point=Edit_Image_Point)
async def gen_edit_img_by_img(
    prompt: Annotated[str, Meta(description="ç¼–è¾‘å›¾ç‰‡çš„æç¤ºè¯")],
    image_id_list: Annotated[list[str], Meta(description="ç¼–è¾‘å›¾ç‰‡çš„åŸºç¡€å›¾ç‰‡IDåˆ—è¡¨")],
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
    model_knowledge: Annotated[Optional[str], Meta(description="æ¨¡å‹çŸ¥è¯†å‚è€ƒï¼Œç”±AIæ ¹æ®ç”¨æˆ·éœ€æ±‚é¢„å…ˆæ£€ç´¢")] = None,
):
    """
    å›¾ç‰‡ç¼–è¾‘å·¥å…·ï¼šå¯¹å·²æœ‰å›¾ç‰‡è¿›è¡Œæ™ºèƒ½ç¼–è¾‘å’Œä¿®æ”¹

    é€‚ç”¨äºï¼š
    - å›¾ç‰‡å†…å®¹çš„æ™ºèƒ½æ›¿æ¢æˆ–ä¿®æ”¹ï¼ˆå¦‚æ¢è£…ã€æ¢èƒŒæ™¯ï¼‰
    - å±€éƒ¨åŒºåŸŸç¼–è¾‘å’Œä¿®å¤
    - å¤šå›¾ç‰‡èåˆæˆ–åˆ›æ„ç¼–è¾‘
    - å›¾åƒä¸­ç‰©ä½“çš„å¢åˆ æ”¹
    - ç»™å›¾ç‰‡æ·»åŠ æ–‡å­—

    å¯ç”¨æ¨¡å‹ï¼š
    - qwen_2511: é€šä¹‰åƒé—®å›¾ç‰‡ç¼–è¾‘æ¨¡å‹
    - banana2: é«˜æ•ˆè½»é‡çº§å›¾ç‰‡ç¼–è¾‘æ¨¡å‹
    - banana_pro: é«˜è´¨é‡å›¾ç‰‡ç¼–è¾‘ä¸“ä¸šæ¨¡å‹

    æ ¹æ®ç”¨æˆ·å¯¹è´¨é‡ã€é€Ÿåº¦ã€æˆæœ¬çš„è¦æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹
    """
    if model is None:
        # å‘åå…¼å®¹ï¼šå¦‚æœAIæ²¡æœ‰é€‰æ‹©æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰çš„RAGæ–¹å¼
        try:
            model = await recommend_model(
                query=f"ç¼–è¾‘å›¾ç‰‡: {prompt}",
                category="image_edit",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(image_edit_workflow.keys()))

    if model is None:
        model = random.choice(list(image_edit_workflow.keys()))

    if model_knowledge:
        logger.info(f"[RHComfyUI] ä½¿ç”¨AIé€‰æ‹©çš„æ¨¡å‹: {model} (åŸºäºçŸ¥è¯†æ£€ç´¢)")

    model_func = image_edit_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")

    image_list = [await RM.get(image_id) for image_id in image_id_list]
    result = await model_func(prompt, image_list)
    return result


@ai_tools(check_func=check_point, point=Music_Point)
async def gen_music(
    style_prompt: Annotated[str, Meta(description="ç”ŸæˆéŸ³ä¹çš„é£æ ¼æç¤ºè¯")],
    lyric_prompt: Annotated[Optional[str], Meta(description="ç”ŸæˆéŸ³ä¹çš„æ­Œè¯æç¤ºè¯")] = None,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
    model_knowledge: Annotated[Optional[str], Meta(description="æ¨¡å‹çŸ¥è¯†å‚è€ƒï¼Œç”±AIæ ¹æ®ç”¨æˆ·éœ€æ±‚é¢„å…ˆæ£€ç´¢")] = None,
):
    """
    éŸ³ä¹ç”Ÿæˆå·¥å…·ï¼šæ ¹æ®é£æ ¼å’Œæ­Œè¯æè¿°ç”ŸæˆéŸ³ä¹

    é€‚ç”¨äºï¼š
    - åˆ›ä½œèƒŒæ™¯éŸ³ä¹ã€é…ä¹ç­‰çº¯éŸ³ä¹
    - æ ¹æ®æ­Œè¯ç”Ÿæˆå¸¦äººå£°çš„æ­Œæ›²
    - å„ç§éŸ³ä¹é£æ ¼çš„åˆ›ä½œï¼ˆæµè¡Œã€å¤å…¸ã€ç”µå­ã€æ‘‡æ»šç­‰ï¼‰
    - æ¸¸æˆé…ä¹ã€è§†é¢‘é…ä¹ç­‰åœºæ™¯éŸ³ä¹ç”Ÿæˆ

    å¯ç”¨æ¨¡å‹ï¼š
    - ace_step1.5: é«˜è´¨é‡éŸ³ä¹ç”Ÿæˆæ¨¡å‹
    """
    if model is None:
        # å‘åå…¼å®¹ï¼šå¦‚æœAIæ²¡æœ‰é€‰æ‹©æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰çš„RAGæ–¹å¼
        try:
            model = await recommend_model(
                query=f"ç”ŸæˆéŸ³ä¹: {style_prompt} {'' if lyric_prompt is None else lyric_prompt}",
                category="music",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(music_workflow.keys()))

    if model is None:
        model = random.choice(list(music_workflow.keys()))

    if model_knowledge:
        logger.info(f"[RHComfyUI] ä½¿ç”¨AIé€‰æ‹©çš„æ¨¡å‹: {model} (åŸºäºçŸ¥è¯†æ£€ç´¢)")

    model_func = music_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(style_prompt, lyric_prompt)
    if result is not None:
        return MessageSegment.record(result)
    return result


@ai_tools(check_func=check_point, point=Speech_Point)
async def gen_speech(
    text: Annotated[str, Meta(description="ç”Ÿæˆè¯­éŸ³çš„æ–‡æœ¬")],
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
    model_knowledge: Annotated[Optional[str], Meta(description="æ¨¡å‹çŸ¥è¯†å‚è€ƒï¼Œç”±AIæ ¹æ®ç”¨æˆ·éœ€æ±‚é¢„å…ˆæ£€ç´¢")] = None,
):
    """
    è¯­éŸ³ç”Ÿæˆå·¥å…·ï¼šå°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³éŸ³é¢‘

    é€‚ç”¨äºï¼š
    - æ–‡å­—æœ—è¯»å’Œæœ‰å£°ä¹¦åˆ¶ä½œ
    - è§†é¢‘é…éŸ³å’Œæ—ç™½ç”Ÿæˆ
    - è¯­éŸ³æ’­æŠ¥å’Œé€šçŸ¥éŸ³æ•ˆ
    - è™šæ‹Ÿä¸»æ’­å’Œæ•°å­—äººé…éŸ³

    å¯ç”¨æ¨¡å‹ï¼š
    - IndexTTS2: é«˜è´¨é‡è¯­éŸ³åˆæˆæ¨¡å‹
    """
    if model is None:
        # å‘åå…¼å®¹ï¼šå¦‚æœAIæ²¡æœ‰é€‰æ‹©æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰çš„RAGæ–¹å¼
        try:
            model = await recommend_model(
                query=f"ç”Ÿæˆè¯­éŸ³: {text}",
                category="speech",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(speech_workflow.keys()))

    if model is None:
        model = random.choice(list(speech_workflow.keys()))

    if model_knowledge:
        logger.info(f"[RHComfyUI] ä½¿ç”¨AIé€‰æ‹©çš„æ¨¡å‹: {model} (åŸºäºçŸ¥è¯†æ£€ç´¢)")

    model_func = speech_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(text)
    if result is not None:
        return MessageSegment.record(result)
    return result


@ai_tools(check_func=check_point, point=Video_Point)
async def gen_video_by_text(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆè§†é¢‘çš„æç¤ºè¯")],
    w: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„å®½åº¦")] = 720,
    h: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„é«˜åº¦")] = 1280,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
    model_knowledge: Annotated[Optional[str], Meta(description="æ¨¡å‹çŸ¥è¯†å‚è€ƒï¼Œç”±AIæ ¹æ®ç”¨æˆ·éœ€æ±‚é¢„å…ˆæ£€ç´¢")] = None,
):
    """
    æ–‡ç”Ÿè§†é¢‘å·¥å…·ï¼šæ ¹æ®æ–‡å­—æè¿°ç”Ÿæˆè§†é¢‘

    é€‚ç”¨äºï¼š
    - ä»é›¶å¼€å§‹åˆ›ä½œåŠ¨ç”»æˆ–çŸ­è§†é¢‘
    - æ¦‚å¿µè§†é¢‘å’ŒåŠ¨æ€è§†è§‰å†…å®¹ç”Ÿæˆ
    - æ•…äº‹æ¿æˆ–è„šæœ¬çš„å¯è§†åŒ–
    - å„ç±»åŠ¨æ€åœºæ™¯çš„åˆ›æ„å±•ç¤º

    å¯ç”¨æ¨¡å‹ï¼š
    - wan2.2_text2video: é«˜è´¨é‡æ–‡ç”Ÿè§†é¢‘æ¨¡å‹
    """
    if model is None:
        # å‘åå…¼å®¹ï¼šå¦‚æœAIæ²¡æœ‰é€‰æ‹©æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰çš„RAGæ–¹å¼
        try:
            model = await recommend_model(
                query=f"ç”Ÿæˆè§†é¢‘: {prompt}",
                category="text2video",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(text2video_workflow.keys()))

    if model is None:
        model = random.choice(list(text2video_workflow.keys()))

    if model_knowledge:
        logger.info(f"[RHComfyUI] ä½¿ç”¨AIé€‰æ‹©çš„æ¨¡å‹: {model} (åŸºäºçŸ¥è¯†æ£€ç´¢)")

    model_func = text2video_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(prompt, w, h)
    if result is not None:
        return MessageSegment.video(result)
    return result


@ai_tools(check_func=check_point, point=Video_Point)
async def gen_video_by_img(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆè§†é¢‘çš„æç¤ºè¯")],
    image_id: Annotated[str, Meta(description="ç”Ÿæˆè§†é¢‘çš„åŸºç¡€å›¾ç‰‡ID")],
    w: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„å®½åº¦")] = 720,
    h: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„é«˜åº¦")] = 1280,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
    model_knowledge: Annotated[Optional[str], Meta(description="æ¨¡å‹çŸ¥è¯†å‚è€ƒï¼Œç”±AIæ ¹æ®ç”¨æˆ·éœ€æ±‚é¢„å…ˆæ£€ç´¢")] = None,
):
    """
    å›¾ç”Ÿè§†é¢‘å·¥å…·ï¼šä»¥å›¾ç‰‡ä¸ºåŸºç¡€ç”ŸæˆåŠ¨æ€è§†é¢‘

    é€‚ç”¨äºï¼š
    - å°†é™æ€å›¾ç‰‡è½¬åŒ–ä¸ºåŠ¨æ€è§†é¢‘
    - å›¾ç‰‡ä¸­çš„é™æ€å…ƒç´ æ·»åŠ åŠ¨æ€æ•ˆæœ
    - ç…§ç‰‡æ´»åŒ–æˆ–è§†é¢‘åŒ–
    - è§†è§‰ç´ æçš„åŠ¨æ€å±•ç¤ºå’Œæ¼”ç»

    å¯ç”¨æ¨¡å‹ï¼š
    - wan2.2_img2video: é«˜è´¨é‡å›¾ç”Ÿè§†é¢‘æ¨¡å‹
    """
    if model is None:
        # å‘åå…¼å®¹ï¼šå¦‚æœAIæ²¡æœ‰é€‰æ‹©æ¨¡å‹ï¼Œä½¿ç”¨åŸæœ‰çš„RAGæ–¹å¼
        try:
            model = await recommend_model(
                query=f"å›¾ç”Ÿè§†é¢‘: {prompt}",
                category="image2video",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(image2video_workflow.keys()))

    if model is None:
        model = random.choice(list(image2video_workflow.keys()))

    if model_knowledge:
        logger.info(f"[RHComfyUI] ä½¿ç”¨AIé€‰æ‹©çš„æ¨¡å‹: {model} (åŸºäºçŸ¥è¯†æ£€ç´¢)")

    model_func = image2video_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    image = await RM.get(image_id)
    result = await model_func(prompt, image, w, h)
    if result is not None:
        return MessageSegment.video(result)
    return result
