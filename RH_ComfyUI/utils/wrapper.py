import random
from typing import Tuple, Optional, Annotated

from PIL import Image
from msgspec import Meta

from gsuid_core.logger import logger
from gsuid_core.models import Event
from gsuid_core.segment import MessageSegment
from gsuid_core.ai_core.register import ai_tools
from gsuid_core.utils.resource_manager import RM

from .model_wrapper import recommend_model
from .comfyui._request import (
    draw_img_by_qwen_2512,
    gen_music_by_ace_step_1_5,
    gen_speech_by_index_tts_2,
    edit_img_by_qwen_edit_2511,
    gen_video_by_img_by_wan2_2,
    gen_video_by_text_by_wan2_2,
    draw_img_by_img_by_qwen_2512,
)
from ..utils.blt.request import (
    edit_img_by_banana2,
    draw_image_by_banana2,
    edit_img_by_banana_pro,
    draw_image_by_banana_pro,
)
from ..utils.database.models import RHBind
from ..rh_config.comfyui_config import RHCOMFYUI_CONFIG

Draw_Point: int = RHCOMFYUI_CONFIG.get_config("Draw_Point").data
Edit_Image_Point: int = RHCOMFYUI_CONFIG.get_config("Edit_Image_Point").data
Music_Point: int = RHCOMFYUI_CONFIG.get_config("Music_Point").data
Speech_Point: int = RHCOMFYUI_CONFIG.get_config("Speech_Point").data
Video_Point: int = RHCOMFYUI_CONFIG.get_config("Video_Point").data

text2image_workflow = {
    "qwen_2512": draw_img_by_qwen_2512,
    "banana2": draw_image_by_banana2,
    "banana_pro": draw_image_by_banana_pro,
}

image2image_workflow = {
    "qwen_2512_with_lora": draw_img_by_img_by_qwen_2512,
}

image_edit_workflow = {
    "qwen_2511": edit_img_by_qwen_edit_2511,
    "banana2": edit_img_by_banana2,
    "banana_pro": edit_img_by_banana_pro,
}

music_workflow = {
    "ace_step1.5": gen_music_by_ace_step_1_5,
}

speech_workflow = {
    "IndexTTS2": gen_speech_by_index_tts_2,
}

text2video_workflow = {
    "wan2.2_text2video": gen_video_by_text_by_wan2_2,
}

image2video_workflow = {
    "wan2.2_img2video": gen_video_by_img_by_wan2_2,
}


async def check_point(ev: Event, point: int) -> Tuple[bool, str]:
    """
    æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç§¯åˆ†
    """
    logger.info(f"[RHComfyUI] check_point: ç”¨æˆ·:{ev.user_id} BotID:{ev.bot_id} æ¶ˆè´¹:{point}")

    bind = await RHBind.deduct_point(
        ev.user_id,
        ev.bot_id,
        point,
    )

    if bind:
        return True, f"ğŸ’ª ç§¯åˆ†å……è¶³ï¼å·²æ‰£é™¤{point}ç§¯åˆ†!\nâœ… æ­£åœ¨ç”Ÿæˆï¼Œé¢„è®¡å°†ç­‰å¾…1åˆ†é’Ÿ..."
    else:
        return False, f"âŒ ç§¯åˆ†ä¸è¶³ï¼éœ€è¦{point}ç§¯åˆ†ï¼"


@ai_tools(check_func=check_point, point=Draw_Point)
async def gen_image_by_text(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„æç¤ºè¯")],
    w: Annotated[int, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„å®½åº¦")] = 720,
    h: Annotated[int, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„é«˜åº¦")] = 1280,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
) -> Image.Image:
    """
    è°ƒç”¨AIæ¨¡å‹è¿›è¡Œæ–‡ç”Ÿå›¾çš„å·¥å…·

    å½“modelå‚æ•°ä¸ºç©ºæ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨æŸ¥è¯¢å‘é‡åº“é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    å¯ç”¨æ¨¡å‹ï¼šqwen_2512, banana2, banana_pro
    """
    if model is None:
        # ä½¿ç”¨RAGæŸ¥è¯¢æ¨èåˆé€‚çš„æ¨¡å‹
        try:
            model = await recommend_model(
                query=f"ç”Ÿæˆå›¾ç‰‡: {prompt}",
                category="text2image",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(text2image_workflow.keys()))

    if model is None:
        model = random.choice(list(text2image_workflow.keys()))

    model_func = text2image_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(prompt, w, h)
    return result


@ai_tools(check_func=check_point, point=Draw_Point)
async def gen_image_by_img(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„æç¤ºè¯")],
    image_id: Annotated[str, Meta(description="ç”Ÿæˆå›¾ç‰‡çš„åŸºç¡€å›¾ç‰‡ID")],
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
) -> Image.Image:
    """
    è°ƒç”¨AIæ¨¡å‹è¿›è¡Œå›¾ç”Ÿå›¾çš„å·¥å…·

    å½“modelå‚æ•°ä¸ºç©ºæ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨æŸ¥è¯¢å‘é‡åº“é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    å¯ç”¨æ¨¡å‹ï¼šqwen_2512_with_lora
    """
    if model is None:
        # ä½¿ç”¨RAGæŸ¥è¯¢æ¨èåˆé€‚çš„æ¨¡å‹
        try:
            model = await recommend_model(
                query=f"å›¾ç”Ÿå›¾: {prompt}",
                category="image2image",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(image2image_workflow.keys()))

    if model is None:
        model = random.choice(list(image2image_workflow.keys()))

    model_func = image2image_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")

    image = await RM.get(image_id)
    result = await model_func(prompt, image)
    return result


@ai_tools(check_func=check_point, point=Edit_Image_Point)
async def gen_edit_img_by_img(
    prompt: Annotated[str, Meta(description="ç¼–è¾‘å›¾ç‰‡çš„æç¤ºè¯")],
    image_id_list: Annotated[list[str], Meta(description="ç¼–è¾‘å›¾ç‰‡çš„åŸºç¡€å›¾ç‰‡IDåˆ—è¡¨")],
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
):
    """
    è°ƒç”¨AIæ¨¡å‹è¿›è¡Œå›¾ç‰‡ç¼–è¾‘çš„å·¥å…·

    å½“modelå‚æ•°ä¸ºç©ºæ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨æŸ¥è¯¢å‘é‡åº“é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    å¯ç”¨æ¨¡å‹ï¼šqwen_2511, banana2, banana_pro
    """
    if model is None:
        # ä½¿ç”¨RAGæŸ¥è¯¢æ¨èåˆé€‚çš„æ¨¡å‹
        try:
            model = await recommend_model(
                query=f"ç¼–è¾‘å›¾ç‰‡: {prompt}",
                category="image_edit",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(image_edit_workflow.keys()))

    if model is None:
        model = random.choice(list(image_edit_workflow.keys()))

    model_func = image_edit_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")

    image_list = [await RM.get(image_id) for image_id in image_id_list]
    result = await model_func(prompt, image_list)
    return result


@ai_tools(check_func=check_point, point=Music_Point)
async def gen_music(
    style_prompt: Annotated[str, Meta(description="ç”ŸæˆéŸ³ä¹çš„é£æ ¼æç¤ºè¯")],
    lyric_prompt: Annotated[Optional[str], Meta(description="ç”ŸæˆéŸ³ä¹çš„æ­Œè¯æç¤ºè¯")] = None,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
):
    """
    è°ƒç”¨AIæ¨¡å‹è¿›è¡ŒéŸ³ä¹ç”Ÿæˆçš„å·¥å…·

    å½“modelå‚æ•°ä¸ºç©ºæ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨æŸ¥è¯¢å‘é‡åº“é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    å¯ç”¨æ¨¡å‹ï¼šace_step1.5
    """
    if model is None:
        # ä½¿ç”¨RAGæŸ¥è¯¢æ¨èåˆé€‚çš„æ¨¡å‹
        try:
            model = await recommend_model(
                query=f"ç”ŸæˆéŸ³ä¹: {style_prompt} {'' if lyric_prompt is None else lyric_prompt}",
                category="music",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(music_workflow.keys()))

    if model is None:
        model = random.choice(list(music_workflow.keys()))

    model_func = music_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(style_prompt, lyric_prompt)
    if result is not None:
        return MessageSegment.record(result)
    return result


@ai_tools(check_func=check_point, point=Speech_Point)
async def gen_speech(
    text: Annotated[str, Meta(description="ç”Ÿæˆè¯­éŸ³çš„æ–‡æœ¬")],
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
):
    """
    è°ƒç”¨AIæ¨¡å‹è¿›è¡Œè¯­éŸ³ç”Ÿæˆçš„å·¥å…·

    å½“modelå‚æ•°ä¸ºç©ºæ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨æŸ¥è¯¢å‘é‡åº“é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    å¯ç”¨æ¨¡å‹ï¼šIndexTTS2
    """
    if model is None:
        # ä½¿ç”¨RAGæŸ¥è¯¢æ¨èåˆé€‚çš„æ¨¡å‹
        try:
            model = await recommend_model(
                query=f"ç”Ÿæˆè¯­éŸ³: {text}",
                category="speech",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(speech_workflow.keys()))

    if model is None:
        model = random.choice(list(speech_workflow.keys()))

    model_func = speech_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(text)
    if result is not None:
        return MessageSegment.record(result)
    return result


@ai_tools(check_func=check_point, point=Video_Point)
async def gen_video_by_text(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆè§†é¢‘çš„æç¤ºè¯")],
    w: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„å®½åº¦")] = 720,
    h: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„é«˜åº¦")] = 1280,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
):
    """
    è°ƒç”¨AIæ¨¡å‹è¿›è¡Œæ–‡ç”Ÿè§†é¢‘çš„å·¥å…·

    å½“modelå‚æ•°ä¸ºç©ºæ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨æŸ¥è¯¢å‘é‡åº“é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    å¯ç”¨æ¨¡å‹ï¼šwan2.2_text2video
    """
    if model is None:
        # ä½¿ç”¨RAGæŸ¥è¯¢æ¨èåˆé€‚çš„æ¨¡å‹
        try:
            model = await recommend_model(
                query=f"ç”Ÿæˆè§†é¢‘: {prompt}",
                category="text2video",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(text2video_workflow.keys()))

    if model is None:
        model = random.choice(list(text2video_workflow.keys()))

    model_func = text2video_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    result = await model_func(prompt, w, h)
    if result is not None:
        return MessageSegment.video(result)
    return result


@ai_tools(check_func=check_point, point=Video_Point)
async def gen_video_by_img(
    prompt: Annotated[str, Meta(description="ç”Ÿæˆè§†é¢‘çš„æç¤ºè¯")],
    image_id: Annotated[str, Meta(description="ç”Ÿæˆè§†é¢‘çš„åŸºç¡€å›¾ç‰‡ID")],
    w: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„å®½åº¦")] = 720,
    h: Annotated[int, Meta(description="ç”Ÿæˆè§†é¢‘çš„é«˜åº¦")] = 1280,
    model: Annotated[Optional[str], Meta(description="ä½¿ç”¨çš„æ¨¡å‹ï¼Œä¸ºç©ºæ—¶AIä¼šæ ¹æ®éœ€æ±‚è‡ªåŠ¨é€‰æ‹©")] = None,
):
    """
    è°ƒç”¨AIæ¨¡å‹è¿›è¡Œå›¾ç”Ÿè§†é¢‘çš„å·¥å…·

    å½“modelå‚æ•°ä¸ºç©ºæ—¶ï¼Œä¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªåŠ¨æŸ¥è¯¢å‘é‡åº“é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    å¯ç”¨æ¨¡å‹ï¼šwan2.2_img2video
    """
    if model is None:
        # ä½¿ç”¨RAGæŸ¥è¯¢æ¨èåˆé€‚çš„æ¨¡å‹
        try:
            model = await recommend_model(
                query=f"å›¾ç”Ÿè§†é¢‘: {prompt}",
                category="image2video",
                fallback=True,
            )
        except Exception as e:
            logger.warning(f"[RHComfyUI][RAG] æ¨¡å‹æ¨èå¤±è´¥ï¼Œä½¿ç”¨éšæœºé€‰æ‹©: {e}")
            model = random.choice(list(image2video_workflow.keys()))

    if model is None:
        model = random.choice(list(image2video_workflow.keys()))

    model_func = image2video_workflow.get(model)
    if model_func is None:
        raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
    image = await RM.get(image_id)
    result = await model_func(prompt, image, w, h)
    if result is not None:
        return MessageSegment.video(result)
    return result
