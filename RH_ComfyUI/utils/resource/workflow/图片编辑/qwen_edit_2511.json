{
  "8": {
    "inputs": {
      "samples": [
        "65",
        0
      ],
      "vae": [
        "10",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "10": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "12": {
    "inputs": {
      "unet_name": "qwen_image_edit_2511_bf16.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "41": {
    "inputs": {
      "image": "a776e7f0d6e533675822bfec0aea43b224b0ae06295d5057efc71ae2444d0385.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "61": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "64": {
    "inputs": {
      "strength": 1,
      "model": [
        "67",
        0
      ]
    },
    "class_type": "CFGNorm",
    "_meta": {
      "title": "CFGNorm"
    }
  },
  "65": {
    "inputs": {
      "seed": 666654940969800,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "64",
        0
      ],
      "positive": [
        "70",
        0
      ],
      "negative": [
        "71",
        0
      ],
      "latent_image": [
        "74",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "67": {
    "inputs": {
      "shift": 3.1,
      "model": [
        "93",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "68": {
    "inputs": {
      "prompt": [
        "103",
        0
      ],
      "clip": [
        "61",
        0
      ],
      "vae": [
        "10",
        0
      ],
      "image1": [
        "73",
        0
      ],
      "image2": [
        "79",
        0
      ],
      "image3": [
        "81",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus (Positive)"
    }
  },
  "69": {
    "inputs": {
      "prompt": "",
      "clip": [
        "61",
        0
      ],
      "vae": [
        "10",
        0
      ],
      "image1": [
        "73",
        0
      ],
      "image2": [
        "81",
        0
      ],
      "image3": [
        "81",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "70": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "68",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "Edit Model Reference Method"
    }
  },
  "71": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "69",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "Edit Model Reference Method"
    }
  },
  "73": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1.5,
      "resolution_steps": 1,
      "image": [
        "41",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "Scale Image to Total Pixels"
    }
  },
  "74": {
    "inputs": {
      "pixels": [
        "73",
        0
      ],
      "vae": [
        "10",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "79": {
    "inputs": {
      "image": "1042074ba105bd8327cbddd8d8267e85823b48b1dd6b87e5f1b8b8568d8b6088.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "81": {
    "inputs": {
      "image": "e33d45ad1758a3b6605345deaefdd84d527bb26a62b414a28c6decdda8e0228c.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "82": {
    "inputs": {
      "width": 928,
      "height": 1664,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "86": {
    "inputs": {
      "direction": "right",
      "match_image_size": true,
      "image1": [
        "90",
        0
      ],
      "image2": [
        "8",
        0
      ]
    },
    "class_type": "ImageConcanate",
    "_meta": {
      "title": "Image Concatenate"
    }
  },
  "90": {
    "inputs": {
      "inputcount": 3,
      "direction": "down",
      "match_image_size": true,
      "Update inputs": null,
      "image_1": [
        "73",
        0
      ],
      "image_2": [
        "79",
        0
      ],
      "image_3": [
        "81",
        0
      ]
    },
    "class_type": "ImageConcatMulti",
    "_meta": {
      "title": "Image Concatenate Multi"
    }
  },
  "93": {
    "inputs": {
      "lora_name": "Qwen-Image-Edit-2511-Lightning-4steps-V1.0-fp32.safetensors",
      "strength_model": 1,
      "model": [
        "12",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "101": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "86",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "103": {
    "inputs": {
      "text": "ËÆ©Âõæ1ÁöÑÂ•≥‰∫∫ÁöÑË°£ÊúçÊõøÊç¢‰∏∫Âõæ2Ê¨æÂºèÁöÑË°£Êúç"
    },
    "class_type": "CR Text",
    "_meta": {
      "title": "üî§ CR Text"
    }
  }
}